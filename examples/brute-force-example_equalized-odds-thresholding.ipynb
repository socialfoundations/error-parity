{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b69330",
   "metadata": {},
   "source": [
    "# Comparison between `error-parity`'s LP solver and a brute-force solver\n",
    "\n",
    "Out of curiosity, this notebook compares the performance and efficiency of the `error-parity` LP formulation against a baseline brute-force solver.\n",
    "\n",
    "**NOTE**: this notebook has extra requirements, install them with:\n",
    "```\n",
    "pip install \"error_parity[dev]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509e4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install \"error-parity[dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01898056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2866f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ran using `error-parity==0.3.11`\n"
     ]
    }
   ],
   "source": [
    "from error_parity import __version__\n",
    "print(f\"Notebook ran using `error-parity=={__version__}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa7fefa",
   "metadata": {},
   "source": [
    "## Given some data (X, Y, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b33f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples: int, n_groups: int, prevalence: float, seed: int):\n",
    "    \"\"\"Helper to generate synthetic features/labels/predictions.\"\"\"\n",
    "\n",
    "    # Construct numpy rng\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Different levels of gaussian noise per group (to induce some inequality in error rates)\n",
    "    group_noise = [0.1 + 0.3 * rng.random() / (1+idx) for idx in range(n_groups)]\n",
    "\n",
    "    # Generate predictions\n",
    "    assert 0 < prevalence < 1\n",
    "    y_score = rng.random(size=n_samples)\n",
    "\n",
    "    # Generate labels\n",
    "    # - define which samples belong to each group\n",
    "    # - add different noise levels for each group\n",
    "    group = rng.integers(low=0, high=n_groups, size=n_samples)\n",
    "    \n",
    "    y_true = np.zeros(n_samples)\n",
    "    for i in range(n_groups):\n",
    "        group_filter = group == i\n",
    "        y_true_groupwise = ((\n",
    "            y_score[group_filter] +\n",
    "            rng.normal(size=np.sum(group_filter), scale=group_noise[i])\n",
    "        ) > (1-prevalence)).astype(int)\n",
    "\n",
    "        y_true[group_filter] = y_true_groupwise\n",
    "\n",
    "    ### Generate features: just use the sample index\n",
    "    # As we already have the y_scores, we can construct the features X\n",
    "    # as the index of each sample, so we can construct a classifier that\n",
    "    # simply maps this index to our pre-generated predictions for this clf.\n",
    "    X = np.arange(len(y_true)).reshape((-1, 1))\n",
    "        \n",
    "    return X, y_true, y_score, group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d326b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GROUPS = 2\n",
    "# N_SAMPLES = 1_000_000\n",
    "N_SAMPLES = 100_000\n",
    "\n",
    "SEED = 23\n",
    "\n",
    "X, y_true, y_score, group = generate_synthetic_data(\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_groups=N_GROUPS,\n",
    "    prevalence=0.25,\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba24bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual global prevalence: 27.2%\n"
     ]
    }
   ],
   "source": [
    "actual_prevalence = np.sum(y_true) / len(y_true)\n",
    "print(f\"Actual global prevalence: {actual_prevalence:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbc24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON_TOLERANCE = 0.05\n",
    "# EPSILON_TOLERANCE = 1.0  # best unconstrained classifier\n",
    "FALSE_POS_COST = 1\n",
    "FALSE_NEG_COST = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc6798",
   "metadata": {},
   "source": [
    "---\n",
    "## Given a trained predictor (that outputs real-valued scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5615f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictor that predicts the synthetically produced scores above\n",
    "predictor = lambda idx: y_score[idx].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54b73d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Comparing LP vs brute-force solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0899f",
   "metadata": {},
   "source": [
    "## 1. Brute-force solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb73fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "from error_parity.evaluation import eval_accuracy_and_equalized_odds\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def binarize_predictions(y_score, group_membership, group_thresholds: dict, seed: int = 42):\n",
    "    \"\"\"Binarizes score predictions using different group thresholds.\"\"\"\n",
    "    # Random number generator\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Results array\n",
    "    y_pred_binary = np.zeros_like(group_membership, dtype=int)\n",
    "\n",
    "    for group_key, group_thrs in group_thresholds.items():\n",
    "        \n",
    "        # Single threshold provided (no randomization)\n",
    "        if not isinstance(group_thrs, Iterable):\n",
    "            low_thr, high_thr = group_thrs, group_thrs\n",
    "        \n",
    "        # Two thresholds provided (partial randomization)\n",
    "        else:\n",
    "            assert len(group_thrs) == 2, f\"Provide exactly 2 thresholds, got {len(group_thrs)}\"\n",
    "            low_thr, high_thr = group_thrs\n",
    "\n",
    "        # Boolean numpy filter for samples of the current group\n",
    "        group_filter = group_membership == group_key\n",
    "        group_score_preds = y_score[group_filter]\n",
    "\n",
    "        # Below low_thr -> negative pred.\n",
    "        y_pred_binary[group_filter & (y_score < low_thr)] = 0\n",
    "\n",
    "        # Above high_thr -> positive pred.\n",
    "        y_pred_binary[group_filter & (y_score > high_thr)] = 1\n",
    "\n",
    "        # Between low_thr and high_thr -> random uniform prediction\n",
    "        if not np.isclose(low_thr, high_thr):\n",
    "            middle_scores_filter = ((y_score >= low_thr) & (y_score <= high_thr))\n",
    "            y_pred_binary[group_filter & middle_scores_filter] = rng.integers(\n",
    "                low=0, high=2, # sampled in [low, high)\n",
    "                size=np.sum(group_filter & middle_scores_filter),\n",
    "            )\n",
    "\n",
    "    # Return binarized predictions\n",
    "    return y_pred_binary\n",
    "\n",
    "\n",
    "def solve_brute_force(\n",
    "        *,\n",
    "        predictor,\n",
    "        tolerance: float,\n",
    "        data_tuple: float,\n",
    "        threshold_ticks_step: float = 1e-2,\n",
    "    ) -> dict:\n",
    "    \"\"\"Brute-force solution for equalized odds problem.\"\"\"\n",
    "\n",
    "    # Unpack data tuple\n",
    "    X_feats, y_labels, s_group = data_tuple\n",
    "\n",
    "    # Generate unique threshold combinations\n",
    "    unique_groups = np.unique(s_group)\n",
    "    group_threshold_combinations = product(*[\n",
    "        ### Deterministic thresholds\n",
    "        # np.arange(0, 1 + threshold_ticks_step, threshold_ticks_step)\n",
    "\n",
    "        ### Randomized thresholds (full search)\n",
    "        [\n",
    "            (lo_thr, hi_thr)\n",
    "            for lo_thr, hi_thr in product(\n",
    "                np.arange(0, 1 + threshold_ticks_step, threshold_ticks_step),\n",
    "                np.arange(0, 1 + threshold_ticks_step, threshold_ticks_step),\n",
    "            )\n",
    "            if lo_thr <= hi_thr\n",
    "        ]\n",
    "        for _ in range(N_GROUPS)\n",
    "    ])\n",
    "\n",
    "    ### Characterizing the best result\n",
    "    ### NOTE: \"best\" is defined as maximizing accuracy constrained by eq_odds <= tolerance\n",
    "\n",
    "    # Threshold combination of the best result\n",
    "    best_combi: tuple = None\n",
    "    \n",
    "    # Accuracy of the best result\n",
    "    best_accuracy: float = None\n",
    "    \n",
    "    # Constraint violation of the best result\n",
    "    best_eq_odds_violation: float = None\n",
    "\n",
    "    # Evaluate all threshold combinations\n",
    "    num_determ_thrs = np.ceil(1 / threshold_ticks_step) + 1\n",
    "    total_combinations = int((num_determ_thrs * (num_determ_thrs + 1) / 2) ** len(unique_groups))\n",
    "\n",
    "    for combi in tqdm(group_threshold_combinations, total=total_combinations):\n",
    "        thrsh_dict = dict(zip(unique_groups, combi))\n",
    "        \n",
    "        # Binarize predictions with this threshold combination\n",
    "        binarized_preds = binarize_predictions(\n",
    "            y_score=y_score,\n",
    "            group_membership=s_group,\n",
    "            group_thresholds=thrsh_dict,\n",
    "        )\n",
    "        \n",
    "        # Evaluate results\n",
    "        curr_result = eval_accuracy_and_equalized_odds(\n",
    "            y_true=y_labels, y_pred_binary=binarized_preds,\n",
    "            sensitive_attr=s_group,\n",
    "        )\n",
    "        \n",
    "        curr_accuracy, curr_eq_odds_violation = curr_result\n",
    "\n",
    "        if best_combi is None or (\n",
    "            best_accuracy < curr_accuracy\n",
    "            and curr_eq_odds_violation <= tolerance):\n",
    "            \n",
    "            # New best found\n",
    "            best_combi = combi\n",
    "            best_accuracy = curr_accuracy\n",
    "            best_eq_odds_violation = curr_eq_odds_violation\n",
    "\n",
    "    # Return solution that fulfills target tolerance optimally\n",
    "    return {\n",
    "        \"group_thresholds\": best_combi,\n",
    "        \"accuracy\": best_accuracy,\n",
    "        \"eq_odds_violation\": best_eq_odds_violation,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a04f2",
   "metadata": {},
   "source": [
    "Run solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04da756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad44ab5ed4244a1ace95f09442c078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 8.16 s, total: 3min 26s\n",
      "Wall time: 4min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'group_thresholds': ((0.7000000000000001, 0.8), (0.7000000000000001, 0.9)),\n",
       " 'accuracy': 0.80763,\n",
       " 'eq_odds_violation': 0.04660537497114363}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "brute_force_solution = solve_brute_force(\n",
    "    predictor=predictor,\n",
    "    tolerance=EPSILON_TOLERANCE,\n",
    "    data_tuple=(X, y_true, group),\n",
    "    threshold_ticks_step=0.1,\n",
    ")\n",
    "\n",
    "brute_force_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c03426",
   "metadata": {},
   "source": [
    "## 2. LP solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44ef577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_parity import RelaxedThresholdOptimizer\n",
    "\n",
    "def solve_lp(predictor, tolerance: float, data_tuple: tuple):\n",
    "    clf = RelaxedThresholdOptimizer(\n",
    "        predictor=predictor,\n",
    "        constraint=\"equalized_odds\",\n",
    "        tolerance=tolerance,\n",
    "        max_roc_ticks=None,  # use full precision\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    X, y_true, group = data_tuple\n",
    "    clf.fit(X=X, y=y_true, group=group)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2905dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 4.96 ms, total: 109 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "postproc_clf = solve_lp(\n",
    "    predictor=predictor,\n",
    "    tolerance=EPSILON_TOLERANCE,\n",
    "    data_tuple=(X, y_true, group),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0494477",
   "metadata": {},
   "source": [
    "## Compare accuracy and constraint violation\n",
    "Assumes `FP_cost == FN_cost == 1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6488eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dummy constant classifier: 72.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy for dummy constant classifier: {max(np.mean(y_true==label) for label in {0, 1}):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be46537",
   "metadata": {},
   "source": [
    "Evaluate predictions realized by LP solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67746b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realized LP accuracy: 82.2%\n",
      "Realized LP eq. odds violation: 5.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary_lp = postproc_clf.predict(X, group=group)\n",
    "\n",
    "lp_acc, lp_eq_odds = eval_accuracy_and_equalized_odds(y_true, y_pred_binary_lp, group)\n",
    "\n",
    "print(f\"Realized LP accuracy: {lp_acc:.1%}\")\n",
    "print(f\"Realized LP eq. odds violation: {lp_eq_odds:.1%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2e2bb",
   "metadata": {},
   "source": [
    "Evaluate predictions realized by brute-force solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6706b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realized BF accuracy: 80.8%\n",
      "Realized BF eq. odds violation: 4.7%\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary_brute_force = binarize_predictions(\n",
    "    y_score=y_score, group_membership=group,\n",
    "    group_thresholds=dict(zip(range(N_GROUPS), brute_force_solution[\"group_thresholds\"])),\n",
    ")\n",
    "\n",
    "bf_acc, bf_eq_odds = eval_accuracy_and_equalized_odds(y_true, y_pred_binary_brute_force, group)\n",
    "\n",
    "print(f\"Realized BF accuracy: {bf_acc:.1%}\")\n",
    "print(f\"Realized BF eq. odds violation: {bf_eq_odds:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f926646",
   "metadata": {},
   "source": [
    "**Conclusion:** brute-force solver took over 4 minutes to exhaustively search over 4356 combinations while the LP solver took 114ms to achieve a superior solution (because of the finer search grid)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
