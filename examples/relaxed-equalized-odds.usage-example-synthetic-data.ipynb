{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b69330",
   "metadata": {},
   "source": [
    "# Achieving _equalized odds_ on synthetic data\n",
    "\n",
    "**NOTE**: this notebook has extra requirements, install them with:\n",
    "```\n",
    "pip install \"error_parity[dev]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01898056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da92fdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ran using `error-parity==0.3.8`\n"
     ]
    }
   ],
   "source": [
    "from error_parity import __version__\n",
    "print(f\"Notebook ran using `error-parity=={__version__}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa7fefa",
   "metadata": {},
   "source": [
    "## Given some data (X, Y, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b33f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples: int, n_groups: int, prevalence: float, seed: int):\n",
    "    \"\"\"Helper to generate synthetic features/labels/predictions.\"\"\"\n",
    "\n",
    "    # Construct numpy rng\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Different levels of gaussian noise per group (to induce some inequality in error rates)\n",
    "    group_noise = [0.1 + 0.3 * rng.random() / (1+idx) for idx in range(n_groups)]\n",
    "\n",
    "    # Generate predictions\n",
    "    assert 0 < prevalence < 1\n",
    "    y_score = rng.random(size=n_samples)\n",
    "\n",
    "    # Generate labels\n",
    "    # - define which samples belong to each group\n",
    "    # - add different noise levels for each group\n",
    "    group = rng.integers(low=0, high=n_groups, size=n_samples)\n",
    "    \n",
    "    y_true = np.zeros(n_samples)\n",
    "    for i in range(n_groups):\n",
    "        group_filter = group == i\n",
    "        y_true_groupwise = ((\n",
    "            y_score[group_filter] +\n",
    "            rng.normal(size=np.sum(group_filter), scale=group_noise[i])\n",
    "        ) > (1-prevalence)).astype(int)\n",
    "\n",
    "        y_true[group_filter] = y_true_groupwise\n",
    "\n",
    "    ### Generate features: just use the sample index\n",
    "    # As we already have the y_scores, we can construct the features X\n",
    "    # as the index of each sample, so we can construct a classifier that\n",
    "    # simply maps this index to our pre-generated predictions for this clf.\n",
    "    X = np.arange(len(y_true)).reshape((-1, 1))\n",
    "        \n",
    "    return X, y_true, y_score, group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d326b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_GROUPS = 4\n",
    "N_GROUPS = 3\n",
    "\n",
    "# N_SAMPLES = 1_000_000\n",
    "N_SAMPLES = 100_000\n",
    "\n",
    "SEED = 23\n",
    "\n",
    "X, y_true, y_score, group = generate_synthetic_data(\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_groups=N_GROUPS,\n",
    "    prevalence=0.25,\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba24bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual global prevalence: 26.5%\n"
     ]
    }
   ],
   "source": [
    "actual_prevalence = np.sum(y_true) / len(y_true)\n",
    "print(f\"Actual global prevalence: {actual_prevalence:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbc24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON_TOLERANCE = 0.05\n",
    "# EPSILON_TOLERANCE = 1.0  # best unconstrained classifier\n",
    "FALSE_POS_COST = 1\n",
    "FALSE_NEG_COST = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc6798",
   "metadata": {},
   "source": [
    "---\n",
    "## Given a trained predictor (that outputs real-valued scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5615f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictor that predicts the synthetically produced scores above\n",
    "predictor = lambda idx: y_score[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af00a5e",
   "metadata": {},
   "source": [
    "## Construct the fair optimal classifier (derived from the given predictor)\n",
    "- Fairness is measured by the equal odds constraint (equal FPR and TPR among groups);\n",
    "    - optionally, this constraint can be relaxed by some small tolerance;\n",
    "- Optimality is measured as minimizing the expected loss,\n",
    "    - parameterized by the given cost of false positive and false negative errors;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f713ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_parity import RelaxedThresholdOptimizer\n",
    "\n",
    "clf = RelaxedThresholdOptimizer(\n",
    "    predictor=predictor,\n",
    "    constraint=\"equalized_odds\",\n",
    "    tolerance=EPSILON_TOLERANCE,\n",
    "    false_pos_cost=FALSE_POS_COST,\n",
    "    false_neg_cost=FALSE_NEG_COST,\n",
    "    max_roc_ticks=None,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbca6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "clf.fit(X=X, y=y_true, group=group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599af3ba",
   "metadata": {},
   "source": [
    "## Plot solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb901f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", rc={'grid.linestyle': ':'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_parity.plotting import plot_postprocessing_solution\n",
    "\n",
    "plot_postprocessing_solution(\n",
    "    postprocessed_clf=clf,\n",
    "    plot_roc_curves=True,\n",
    "    plot_roc_hulls=True,\n",
    "    dpi=200, figsize=(5, 5),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d213c",
   "metadata": {},
   "source": [
    "---\n",
    "## Plot realized ROC points\n",
    "> realized ROC points will converge to the theoretical solution for larger datasets, but some variance is expected for smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set group-wise colors and global color\n",
    "palette = sns.color_palette(n_colors=N_GROUPS + 1)\n",
    "global_color = palette[0]\n",
    "all_group_colors = palette[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_parity.roc_utils import compute_roc_point_from_predictions\n",
    "\n",
    "plot_postprocessing_solution(\n",
    "    postprocessed_clf=clf,\n",
    "    plot_roc_curves=True,\n",
    "    plot_roc_hulls=True,\n",
    "    dpi=200, figsize=(5, 5),\n",
    ")\n",
    "\n",
    "# Compute predictions\n",
    "y_pred_binary = clf(X, group=group)\n",
    "\n",
    "# Plot the group-wise points found\n",
    "realized_roc_points = list()\n",
    "for idx in range(N_GROUPS):\n",
    "\n",
    "    # Evaluate triangulation of target point as a randomized clf\n",
    "    group_filter = group == idx\n",
    "\n",
    "    curr_realized_roc_point = compute_roc_point_from_predictions(y_true[group_filter], y_pred_binary[group_filter])\n",
    "    realized_roc_points.append(curr_realized_roc_point)\n",
    "\n",
    "    plt.plot(\n",
    "        curr_realized_roc_point[0], curr_realized_roc_point[1],\n",
    "        color=all_group_colors[idx],\n",
    "        marker=\"*\", markersize=8,\n",
    "        lw=0,\n",
    "    )\n",
    "\n",
    "realized_roc_points = np.vstack(realized_roc_points)\n",
    "\n",
    "# Plot actual global classifier performance\n",
    "global_clf_realized_roc_point = compute_roc_point_from_predictions(y_true, y_pred_binary)\n",
    "plt.plot(\n",
    "    global_clf_realized_roc_point[0], global_clf_realized_roc_point[1],\n",
    "    color=global_color,\n",
    "    marker=\"*\", markersize=8,\n",
    "    lw=0,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8db9a56",
   "metadata": {},
   "source": [
    "### Compute distances between theorized ROC points and empirical ROC points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances to group-wise targets:\n",
    "for i, (target_point, actual_point) in enumerate(zip(clf.groupwise_roc_points, realized_roc_points)):\n",
    "    dist = np.linalg.norm(target_point - actual_point, ord=2)\n",
    "    print(f\"Group {i}: l2 distance from target to realized point := {dist:.3%}\")\n",
    "\n",
    "# Distance to global target point:\n",
    "dist = np.linalg.norm(clf.global_roc_point - global_clf_realized_roc_point, ord=2)\n",
    "print(f\"Global l2 distance from target to realized point   := {dist:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0494477",
   "metadata": {},
   "source": [
    "### Compute performance differences\n",
    "> assumes FP_cost == FN_cost == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from error_parity.roc_utils import calc_cost_of_point\n",
    "\n",
    "# Empirical\n",
    "accuracy_val = accuracy_score(y_true, y_pred_binary)\n",
    "\n",
    "# Theoretical\n",
    "theoretical_global_cost = calc_cost_of_point(\n",
    "    fpr=clf.global_roc_point[0],\n",
    "    fnr=1 - clf.global_roc_point[1],\n",
    "    prevalence=y_true.sum() / len(y_true),\n",
    ")\n",
    "\n",
    "print(f\"Actual accuracy: \\t\\t\\t{accuracy_val:.3%}\")\n",
    "print(f\"Actual error rate (1 - Acc.):\\t\\t{1 - accuracy_val:.3%}\")\n",
    "print(f\"Theoretical cost of solution found:\\t{theoretical_global_cost:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2259911",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy for dummy constant classifier: {max(np.mean(y_true==label) for label in {0, 1}):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ebc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_parity.evaluation import eval_accuracy_and_equalized_odds\n",
    "lp_acc, lp_eq_odds = eval_accuracy_and_equalized_odds(y_true, y_pred_binary, group)\n",
    "\n",
    "print(f\"Realized LP accuracy:\\t {lp_acc:.1%}\")\n",
    "print(f\"Realized LP eq. odds violation: {lp_eq_odds:.1%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d590d262",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Plot postprocessing Pareto frontier\n",
    "> i.e., all attainable optimal trade-offs for this predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf828fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_parity.pareto_curve import compute_postprocessing_curve\n",
    "\n",
    "postproc_results_df = compute_postprocessing_curve(\n",
    "    model=predictor,\n",
    "    fit_data=(X, y_true, group),\n",
    "    eval_data={\n",
    "        \"fit\": (X, y_true, group),\n",
    "    },\n",
    "    fairness_constraint=\"equalized_odds\",\n",
    "    bootstrap=True,\n",
    "    seed=SEED,\n",
    "    y_fit_pred_scores=predictor(X),\n",
    "    predict_method=\"__call__\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789ef9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from error_parity.plotting import plot_postprocessing_frontier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plot_postprocessing_frontier(\n",
    "    postproc_results_df,\n",
    "    perf_metric=\"accuracy\",\n",
    "    disp_metric=\"equalized_odds_diff\",\n",
    "    show_data_type=\"fit\",\n",
    "    constant_clf_perf=max((y_true == const_pred).mean() for const_pred in {0, 1}),\n",
    ")\n",
    "\n",
    "plt.xlabel(r\"accuracy $\\rightarrow$\")\n",
    "plt.ylabel(r\"equalized odds violation $\\leftarrow$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
